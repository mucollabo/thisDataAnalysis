{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 [윤기태]\n",
    "\n",
    "https://github.com/yoonkt200/python-data-analysis\n",
    "\n",
    "[MIT License](https://github.com/yoonkt200/python-data-analysis/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (가제) 파이썬 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1) 나무위키 최신 변경 문서의 키워드 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바로가기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [<Step1. 크롤링> : 크롤링으로 웹 데이터 가져오기](#<Step1.-크롤링>-:-크롤링으로-웹-데이터-가져오기)\n",
    "    - [BeautifulSoup을 이용한 웹 크롤링]\n",
    "    - [나무위키 최근변경 데이터 크롤링]\n",
    "- [<Step2. 추출> : 키워드 추출](#<Step2.-추출>-:-키워드-추출)\n",
    "    - [텍스트 데이터 전처리]\n",
    "    - [말뭉치 만들기]\n",
    "    - [konlpy를 이용한 키워드 추출]\n",
    "    - [키워드 가다듬기]\n",
    "- [<Step3. 시각화> : 워드 클라우드 시각화](#<Step3.-시각화>-:-워드-클라우드-시각화)\n",
    "    - [pytagcloud 사용하기]\n",
    "    - [나무위키 키워드 시각화]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step1. 크롤링> : 크롤링으로 웹 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [BeautifulSoup을 이용한 웹 크롤링]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 코드 실행을 위해, anaconda prompt 혹은 Terminal에서 아래와 같은 패키지들을 설치해 줍니다.\n",
    "    - (env_name) `pip install requests`\n",
    "    - (env_name) `pip install beautifulsoup4`\n",
    "    - (env_name) `pip install lxml`\n",
    "- 혹은 아래의 코드로 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (2.25.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (4.9.3)\r\n",
      "Requirement already satisfied: lxml in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (4.6.3)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (from requests) (4.0.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (from requests) (1.26.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (from requests) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (from requests) (2.10)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/charles/Documents/GitHub/thisDataAnalysis/venv/lib/python3.7/site-packages (from beautifulsoup4) (2.2.1)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/charles/Documents/GitHub/thisDataAnalysis/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 페이지 리스트 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-49fb7432ec75>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0msoup\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBeautifulSoup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhtml\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'lxml'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mcontents_table\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msoup\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"table\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mtable_body\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcontents_table\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tbody\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0mtable_rows\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtable_body\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tr\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 크롤링할 사이트 주소를 정의합니다.\n",
    "source_url = \"https://namu.wiki/RecentChanges\"\n",
    "\n",
    "# 사이트의 html 구조에 기반하여 크롤링을 수행합니다.\n",
    "req = requests.get(source_url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name=\"table\")\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a태그의 href 속성을 리스트로 추출하여, 크롤링 할 페이지 리스트를 생성합니다.\n",
    "page_url_base = \"https://namu.wiki\"\n",
    "page_urls = []\n",
    "for index in range(0, len(table_rows)):\n",
    "    first_td = table_rows[index].find_all('td')[0]\n",
    "    td_url = first_td.find_all('a')\n",
    "    if len(td_url) > 0:\n",
    "        page_url = page_url_base + td_url[0].get('href')\n",
    "        if 'png' not in page_url:\n",
    "            page_urls.append(page_url)\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "for page in page_urls[:5]:\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 페이지내 텍스트 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req = requests.get(page_urls[0])\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name=\"article\")\n",
    "title = contents_table.find_all('h1')[0]\n",
    "category = contents_table.find_all('ul')[0]\n",
    "content_paragraphs = contents_table.find_all(name=\"div\", attrs={\"class\":\"wiki-paragraph\"})\n",
    "content_corpus_list = []\n",
    "\n",
    "for paragraphs in content_paragraphs:\n",
    "    content_corpus_list.append(paragraphs.text)\n",
    "content_corpus = \"\".join(content_corpus_list)\n",
    "\n",
    "print(title.text)\n",
    "print(\"\\n\")\n",
    "print(category.text)\n",
    "print(\"\\n\")\n",
    "print(content_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [나무위키 최근변경 데이터 크롤링]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 데이터를 데이터 프레임으로 만들기 위해 준비합니다.\n",
    "columns = ['title', 'category', 'content_text']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 각 페이지별 '제목', '카테고리', '본문' 정보를 데이터 프레임으로 만듭니다.\n",
    "for page_url in page_urls:\n",
    "\n",
    "    # 사이트의 html 구조에 기반하여 크롤링을 수행합니다.\n",
    "    req = requests.get(page_url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    contents_table = soup.find(name=\"article\")\n",
    "    title = contents_table.find_all('h1')[0]\n",
    "    \n",
    "    # 카테고리 정보가 없는 경우를 확인합니다.\n",
    "    if len(contents_table.find_all('ul')) > 0:\n",
    "        category = contents_table.find_all('ul')[0]\n",
    "    else:\n",
    "        category = None\n",
    "        \n",
    "    content_paragraphs = contents_table.find_all(name=\"div\", attrs={\"class\":\"wiki-paragraph\"})\n",
    "    content_corpus_list = []\n",
    "    \n",
    "    # 페이지 내 제목 정보에서 개행 문자를 제거한 뒤 추출합니다. 만약 없는 경우, 빈 문자열로 대체합니다.\n",
    "    if title is not None:\n",
    "        row_title = title.text.replace(\"\\n\", \" \")\n",
    "    else:\n",
    "        row_title = \"\"\n",
    "    \n",
    "    # 페이지 내 본문 정보에서 개행 문자를 제거한 뒤 추출합니다. 만약 없는 경우, 빈 문자열로 대체합니다.\n",
    "    if content_paragraphs is not None:\n",
    "        for paragraphs in content_paragraphs:\n",
    "            if paragraphs is not None:\n",
    "                content_corpus_list.append(paragraphs.text.replace(\"\\n\", \" \"))\n",
    "            else:\n",
    "                content_corpus_list.append(\"\")\n",
    "    else:\n",
    "        content_corpus_list.append(\"\")\n",
    "        \n",
    "    # 페이지 내 카테고리정보에서 “분류”라는 단어와 개행 문자를 제거한 뒤 추출합니다. 만약 없는 경우, 빈 문자열로 대체합니다.\n",
    "    if category is not None:\n",
    "        row_category = category.text.replace(\"\\n\", \" \")\n",
    "    else:\n",
    "        row_category = \"\"\n",
    "    \n",
    "    # 모든 정보를 하나의 데이터 프레임에 저장합니다.\n",
    "    row = [row_title, row_category, \"\".join(content_corpus_list)]\n",
    "    series = pd.Series(row, index=df.columns)\n",
    "    df = df.append(series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임을 출력합니다.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step2. 추출> : 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [텍스트 데이터 전처리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거합니다.\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글의 정규표현식을 나타냅니다.\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_cleaning(df['content_text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 피처마다 데이터 전처리를 적용합니다.\n",
    "df['title'] = df['title'].apply(lambda x: text_cleaning(x))\n",
    "df['category'] = df['category'].apply(lambda x: text_cleaning(x))\n",
    "df['content_text'] = df['content_text'].apply(lambda x: text_cleaning(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [말뭉치 만들기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 피처마다 말뭉치를 생성합니다.\n",
    "title_corpus = \"\".join(df['title'].tolist())\n",
    "category_corpus = \"\".join(df['category'].tolist())\n",
    "content_corpus = \"\".join(df['content_text'].tolist())\n",
    "print(title_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [konlpy를 이용한 키워드 추출]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 코드 실행을 위해, anaconda prompt 혹은 Terminal에서 아래와 같은 패키지들을 설치해 줍니다.\n",
    "- 아래의 방법으로 설치해도 실행되지 않는다면, http://konlpy.org/ko/latest/install/ 를 참고하세요.\n",
    "    - Install\n",
    "        - 1. Java를 설치합니다. (https://java.com/ko/download/)\n",
    "        - 2. c++ 컴파일러를 설치합니다. \n",
    "            - 윈도우 : `Microsoft Visual C++ 14.0` 설치 권장, https://visualstudio.microsoft.com/ko/downloads/\n",
    "            - Mac OS : `Xcode` 설치 권장\n",
    "            - Linux : `gcc` 설치 권장\n",
    "        - 3. 아래와 같은 파이썬 패키지를 설치합니다. **konlpy 버전을 반드시 0.5.1로 해주어야 합니다. 2020년 현재(9월) 기준, 최신 버전 konlpy 에서는 일부 개발환경에서 자바 에러가 발생합니다.**\n",
    "            - (env_name) `pip install konlpy==0.5.1`\n",
    "            - (env_name) `pip install jpype1`\n",
    "            - (env_name) `pip install Jpype1-py3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# konlpy의 형태소 분석기로 명사 단위의 키워드를 추출합니다.\n",
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(content_corpus)\n",
    "count = Counter(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [키워드 가다듬기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 한글자 키워드 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글자 키워드를 제거합니다.\n",
    "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
    "print(remove_char_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 약식 불용어사전 예시 파일입니다. 출처 - (https://www.ranks.nl/stopwords/korean)\n",
    "korean_stopwords_path = \"../data/korean_stopwords.txt\"\n",
    "\n",
    "# 텍스트 파일을 오픈합니다.\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나무위키 페이지에 맞는 불용어를 추가합니다.\n",
    "namu_wiki_stopwords = ['상위', '문서', '내용', '누설', '아래', '해당', '설명', '표기', '추가', '모든', '사용', '매우', '가장',\n",
    "                       '줄거리', '요소', '상황', '편집', '틀', '경우', '때문', '모습', '정도', '이후', '사실', '생각', '인물', \n",
    "                       '이름', '년월']\n",
    "for stopword in namu_wiki_stopwords:\n",
    "    stopwords.append(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 데이터에서 불용어를 제거합니다.\n",
    "remove_char_counter = Counter({x : remove_char_counter[x] for x in count if x not in stopwords})\n",
    "print(remove_char_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step3. 시각화> : 워드 클라우드 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [pytagcloud 사용하기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 코드 실행을 위해, anaconda prompt 혹은 Terminal에서 아래와 같은 패키지들을 설치해 줍니다.\n",
    "    - (env_name) `pip install pytagcloud pygame simplejson`\n",
    "- 그리고 아래와 같은 경로에 한글 폰트(예: NanumBarunGothic.ttf) 파일을 옮깁니다. \n",
    "    - Mac OS : /{anaconda_path}/envs/{env_name}/lib/python3.7/site-packages/pytagcloud/fonts\n",
    "    - Windosw OS : \\{anaconda_path}\\envs\\{env_name}\\Lib\\site-packages\\pytagcloud\\fonts\n",
    "    - `폰트 다운로드 : http://hangeul.naver.com/webfont/NanumGothic/NanumGothic.ttf`\n",
    "- 파일을 옮긴 후, 파이썬 가상환경을 재실행 하여 주피터를 다시 실행해줍니다. 그래도 아래의 코드가 실행되지 않는 경우는 다음과 같은 작업을 수행합니다.\n",
    "    - 위의 경로에서 font.json 파일을 편집합니다.\n",
    "    - 아래와 같은 코드를 추가하고 font.json 파일을 저장합니다.\n",
    "    - {\n",
    "                \"name\": \"NanumGothic\",\n",
    "                \"ttf\": \"NanumGothic.ttf\",\n",
    "                \"web\": \"http://fonts.googleapis.com/css?family=Nanum+Gothic\"\n",
    "        },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pytagcloud\n",
    "import webbrowser\n",
    "\n",
    "# 가장 출현 빈도수가 높은 40개의 단어를 선정합니다.\n",
    "ranked_tags = remove_char_counter.most_common(40)\n",
    "\n",
    "# pytagcloud로 출력할 40개의 단어를 입력합니다. 단어 출력의 최대 크기는 80으로 제한합니다.\n",
    "taglist = pytagcloud.make_tags(ranked_tags, maxsize=80)\n",
    "\n",
    "# pytagcloud 이미지를 생성합니다. 폰트는 나눔 고딕을 사용합니다.\n",
    "pytagcloud.create_tag_image(taglist, 'wordcloud.jpg', size=(900, 600), fontname='NanumGothic', rectangular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 이미지를 주피터 노트북상에서 출력합니다.\n",
    "from IPython.display import Image\n",
    "Image(filename='wordcloud.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [나무위키 키워드 시각화]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 제목 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(title_corpus)\n",
    "count = Counter(nouns)\n",
    "\n",
    "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
    "remove_char_counter = Counter({x : remove_char_counter[x] for x in count if x not in stopwords})\n",
    "\n",
    "ranked_tags = remove_char_counter.most_common(40)\n",
    "taglist = pytagcloud.make_tags(ranked_tags, maxsize=80)\n",
    "pytagcloud.create_tag_image(taglist, 'title_wordcloud.jpg', size=(900, 600), fontname='NanumGothic', rectangular=False)\n",
    "\n",
    "Image(filename='title_wordcloud.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 카테고리 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(category_corpus)\n",
    "count = Counter(nouns)\n",
    "\n",
    "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
    "remove_char_counter = Counter({x : remove_char_counter[x] for x in count if x not in stopwords})\n",
    "\n",
    "ranked_tags = remove_char_counter.most_common(40)\n",
    "taglist = pytagcloud.make_tags(ranked_tags, maxsize=80)\n",
    "pytagcloud.create_tag_image(taglist, 'category_wordcloud.jpg', size=(900, 600), fontname='NanumGothic', rectangular=False)\n",
    "\n",
    "Image(filename='category_wordcloud.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}